<!DOCTYPE html> <html lang="de"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Vision Transformers for Particle Physics | Gerrit Bickendorf </title> <meta name="author" content="Gerrit Bickendorf"> <meta name="description" content="Using recent vision transformer improvement to see new particles"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gbickendorf.github.io/projects/transformer/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Gerrit</span> Bickendorf </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Vision Transformers for Particle Physics</h1> <p class="post-description">Using recent vision transformer improvement to see new particles</p> </header> <article> <h2 id="synopsis">Synopsis</h2> <p>Here, we summarize the key points of our <a href="https://arxiv.org/pdf/2406.03096" rel="external nofollow noopener" target="_blank">publication</a>. We discuss the benefits of using machine learning to identify our signal model and explain how images are defined to leverage computer vision techniques. We demonstrate that there is no need to reinvent the wheel in machine learning; instead, significant improvements can be achieved by applying modern models developed by researchers at Google. These improvements are so substantial that they should survive even with a full application.</p> <h2 id="introduction">Introduction</h2> <p>In this section, we outline the main points of our publication, <a href="https://arxiv.org/pdf/2406.03096" rel="external nofollow noopener" target="_blank">Learning to see R-parity violating scalar top decays</a>. In high-energy particle physics, our goal is to understand the fundamental physics underlying the phenomena observed in experiments. The field is highly advanced, enabling us to accurately predict almost all phenomena observed at the LHC. However, determining whether observed collisions stem from known processes or something new is a complex task that depends on precise statistical modeling. To enhance statistical significance, we must filter out known events while retaining as many potentially interesting events as possible. For some signal models, this is particularly challenging because their signatures in traditional observables are weak. Consequently, more sophisticated methods are required, moving beyond classical, hand-crafted observables.</p> <h2 id="signal-model">Signal model</h2> <p>The signal model of interest belongs to the class of supersymmetric extensions of the Standard Model. The process, illustrated in the accompanying Feynman diagram, can be described as follows: two protons are accelerated to high energies and then collided head-on. The energy from this collision is used to create additional particles, specifically two scalar top quarks (stops). These stops, which have masses between 700 and 1200 GeV, behave similarly to ordinary top quarks but eventually decay into one ordinary top quark and one neutralino. The neutralino, weighing between 100 and 500 GeV, then rapidly decays into three ordinary quarks.</p> <div class="row justify-content-sm-center"> <div class="col-sm-5 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/stopfeyn-480.webp 480w,/assets/img/stopfeyn-800.webp 800w,/assets/img/stopfeyn-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/stopfeyn.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Stop pair production Feynman diagram" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Since the signal results in the production of two top quarks, which are relatively easy to isolate, preselections are made to specifically target these top quarks. After preselection, the only significant background process is the pair production of top quarks. The challenge then lies in determining whether a given event is due to stop-pair or top-pair production.</p> <p>This process is challenging to detect because it is fully hadronic, and the LHC, being a hadron collider, has many known processes that can mimic this signal. Moreover, the signature is quite subtle, typically resulting in two top quarks and two wide jets from the neutralinos. Given the abundance of top quarks at the LHC and the difficulties in reconstructing the wide jets, which are prone to significant errors, a more refined technique is required to distinguish the signal from ordinary physics.</p> <h2 id="from-collisions-to-images">From Collisions to Images</h2> <p>One approach to addressing this problem is to closely examine what the detector perceives as a jet. Jets are clusters of particles that ideally originate from the same initial particle. When these particles interact with the detector, they deposit energy, which the detector measures. In this sense, a detector functions similarly to a camera. The spatial dimensions of a detector image correspond to angular positions, while the channels of a standard image (typically red, green, and blue) are replaced by subdetectors in this case, such as the hadronic or electromagnetic calorimeter or tracker. The brightness or pixel intensity represents the deposited energy. By analyzing these images, one can attempt to predict the production mechanism, which forms the core of our publication. The average signal and background images are displayed below.</p> <div class="row justify-content-sm-center"> <div class="col-sm-5 mt-5 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/avg-480.webp 480w,/assets/img/avg-800.webp 800w,/assets/img/avg-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/avg.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Average jet image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="machine-learning-and-computer-vision">Machine learning and computer vision</h2> <p>Classifying images is a well-known challenge in machine learning, specifically in computer vision. One of the most successful and widely used methods for this task is the Convolutional Neural Network (CNN). A CNN works by comparing a fixed-size local patch of an image with a learnable filter, performing this comparison across the entire image. The resulting similarity scores create a new image, known as a feature map. For example, when distinguishing between images of cats and dogs, a CNN might initially focus on detecting edges, which highlight the most significant parts of the image. Smooth areas without much variation typically provide less useful information. Consequently, the CNN is likely to first learn a filter that enhances edges in the feature maps. By passing these feature maps through successive convolutional layers, the network can gradually identify more complex features, such as cat-like ears or eyes, which are crucial for recognizing the animal.</p> <p>The effectiveness of CNNs largely stems from their focus on local information, allowing them to deliver impressive results with relatively low computational costs. However, recent advancements in computational power at consumer-level prices have enabled the development of more sophisticated techniques. One such innovation is the attention mechanism, which, although computationally demanding, allows for the use of global information—where every input is connected to all other inputs without any inherent ordering. This mechanism is central to the functionality of transformers, a technology that has gained significant attention, especially with the rise of models like ChatGPT (where the ‘T’ stands for transformer). Transformers have revolutionized natural language processing, and their success has sparked interest in applying them to image processing as well.</p> <p>We employ two models, <a href="https://arxiv.org/abs/2106.04803" rel="external nofollow noopener" target="_blank">CoAtNet</a> and <a href="https://arxiv.org/abs/2204.01697" rel="external nofollow noopener" target="_blank">MaxViT</a>, both of which incorporate transformers. Studies introducing these models have demonstrated significant performance improvements over CNNs, particularly with large datasets. Given that physicists excel at working with large datasets, we train both models on jet images and compare their performance against CNNs.</p> <h2 id="training">Training</h2> <p>Our Monte Carlo simulations, which model proton collisions, are highly accurate, allowing us to train on simulated images effectively. To ensure that the model distinguishes between signal and background jets without being influenced by unrelated correlations, we ensure that the signal jets originate from a direction close to the truth-level neutralino. We normalize the pixel intensity by dividing by the maximum value, thereby removing scale-related information, which we reintroduce by feeding the jet mass into the classification network. This is achieved by appending the mass value to the output of the vision component of the model. In total, we train on nearly 6 million images.</p> <h2 id="results">Results</h2> <p>In a practical application, these models would typically serve as inputs to a more sophisticated statistical analysis. However, our proof of concept is focused on demonstrating the models’ effectiveness, so we quantify performance using the metric \(\epsilon_S/ \sqrt{\epsilon_B}\), where \(\epsilon_S\) and \(\epsilon_B\) represent the well-known true-positive and false-positive rates, respectively, after applying a threshold to the output neuron.</p> <p>The performance results for the test set are illustrated below. The labels AK08, AK10, and AK14 correspond to the allowed radii of the respective jets, which essentially represent progressively larger active areas of the detector image.</p> <div class="row justify-content-sm-center"> <div class="col-sm-6 mt-5 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/perf1-480.webp 480w,/assets/img/perf1-800.webp 800w,/assets/img/perf1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/perf1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="SIC of all models" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>It is evident that the largest jet images yield the most powerful classifications, with both transformer-based models significantly outperforming the traditional CNN. The improvements observed in the original publications translate well into the context of particle physics, which is a key result of our study.</p> <p>To assess the raw performance of these models, we conducted a simple mock analysis. In this analysis, we combined additional classical features with the predictions from the largest AK14 jets and fed them into a gradient boosted decision tree. Both background and signal events were normalized to the expected event counts used in current analyses by the CMS and ATLAS collaborations. We then compared the 95% confidence level (C.L.) excluded masses for each of the three computer vision models against those obtained from a decision tree that only used classical features.</p> <div class="row justify-content-sm-center"> <div class="col-sm-6 mt-5 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/perf2-480.webp 480w,/assets/img/perf2-800.webp 800w,/assets/img/perf2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/perf2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Entension of the excluded stop mass range" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>The CNN demonstrates relatively weak performance, contributing only marginally to expanding the excluded parameter space. In contrast, both transformer-based models show a significant advantage, excluding stop masses that are 60 GeV to even 100 GeV higher. This substantial improvement highlights the potential of simply switching to a modern transformer-based architecture to achieve far superior results.</p> <h2 id="conclusion">Conclusion</h2> <p>In conclusion, our study demonstrates that modern transformer-based models significantly outperform traditional CNNs in classifying jet images, leading to a substantial increase in the excluded stop masses. This improvement underscores the value of adopting cutting-edge machine learning techniques in high-energy physics. For a more detailed exploration of our methods and findings, we encourage you to read the full publication.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Gerrit Bickendorf. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"Science and fun projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"Here you can find my public repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"projects-learning-the-density-of-physics",title:"Learning the Density of Physics",description:"An easy introduction to resonant anomaly detection",section:"Projects",handler:()=>{window.location.href="/projects/cathode/"}},{id:"projects-from-datamining-to-a-raceplan",title:"From Datamining to a Raceplan",description:"How to become faster at rowing with Python",section:"Projects",handler:()=>{window.location.href="/projects/elfsteden/"}},{id:"projects-raspberry-pi-geiger-counter",title:"Raspberry Pi Geiger Counter",description:"Combining a Raspberry Pi with a cheap self-soldered Geiger counter",section:"Projects",handler:()=>{window.location.href="/projects/radiation/"}},{id:"projects-vision-transformers-for-particle-physics",title:"Vision Transformers for Particle Physics",description:"Using recent vision transformer improvement to see new particles",section:"Projects",handler:()=>{window.location.href="/projects/transformer/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%62%69%63%6B%65%6E%64%6F%72%66@%75%6E%69-%62%6F%6E%6E.%64%65","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/gerrit-bickendorf# your LinkedIn user name","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>